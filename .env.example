# Italian Real Estate Pipeline - Environment Configuration
# Copy this file to .env and customize the values

# =============================================================================
# MongoDB Configuration
# =============================================================================
MONGODB_HOST=mongodb
MONGODB_PORT=27017
MONGODB_DATALAKE_NAME=mongodb_datalake
MONGODB_WAREHOUSE_NAME=mongodb_warehouse
# Optional MongoDB auth (leave blank to disable)
MONGODB_USER=
MONGODB_PASSWORD=
MONGODB_AUTH_SOURCE=admin

# =============================================================================
# PostgreSQL Configuration
# =============================================================================
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=changeme
POSTGRES_DATABASE=postgres_warehouse

# =============================================================================
# Airflow Configuration
# =============================================================================
AIRFLOW_UID=1000
AIRFLOW__CORE__EXECUTOR=LocalExecutor
AIRFLOW__CORE__FERNET_KEY=our-secret-key-here
AIRFLOW__WEBSERVER__SECRET_KEY=your-secret-key-here
AIRFLOW__CORE__LOAD_EXAMPLES=false

# Airflow metadata DB credentials
AIRFLOW_DB_USER=airflow
AIRFLOW_DB_PASSWORD=airflow
AIRFLOW_DB_NAME=airflow

# Airflow admin (UI/API) user
AIRFLOW_ADMIN_USER=admin
AIRFLOW_ADMIN_PASSWORD=admin
AIRFLOW_ADMIN_EMAIL=admin@example.com
AIRFLOW_ADMIN_FIRSTNAME=Admin
AIRFLOW_ADMIN_LASTNAME=User

# =============================================================================
# Airflow API (used by the TUI for scrape orchestration)
# =============================================================================
AIRFLOW_API_BASE_URL=http://airflow-webserver:8080/api/v1
AIRFLOW_API_USER=admin
AIRFLOW_API_PASSWORD=admin

# =============================================================================
# Scraping Configuration
# =============================================================================
# Note: scraping extraction is redacted in the public portfolio version.
SCRAPING_USE_SELENIUM=0
SCRAPING_SELENIUM_HEADLESS=true
SCRAPING_SELENIUM_PROFILE_DIR=/opt/selenium-profile
SCRAPING_HUMANIZE=0
SCRAPING_HUMANIZE_MIN_WAIT=0.5
SCRAPING_HUMANIZE_MAX_WAIT=3.0
SCRAPING_HUMANIZE_SCROLL_MIN=1
SCRAPING_HUMANIZE_SCROLL_MAX=5
SCRAPING_HUMANIZE_SCROLL_WAIT_MIN=0.5
SCRAPING_HUMANIZE_SCROLL_WAIT_MAX=1.5
SCRAPING_POLITE_MODE=0
SCRAPING_POLITE_MIN_WAIT=1.0
SCRAPING_POLITE_MAX_WAIT=5.0
SCRAPING_POLITE_MAX_RETRIES=5
SCRAPING_POLITE_BACKOFF_BASE=2.0
SCRAPING_POLITE_MAX_ACTIVE_TASKS=1
HTTP_SEMAPHORE_LIMIT=1
SCRAPING_POOL_NAME=scrape_pool
SCRAPING_POOL_SLOTS=1

# =============================================================================
# GPU Configuration (optional - for synthetic data generation)
# =============================================================================
TF_FORCE_GPU_ALLOW_GROWTH=true
NVIDIA_VISIBLE_DEVICES=all
TF_CPP_MIN_LOG_LEVEL=2
